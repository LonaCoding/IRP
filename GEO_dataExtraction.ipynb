{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import wget\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import tarfile as tf\n",
    "\n",
    "try:\n",
    "    os.mkdir('VPA')\n",
    "except: #if file already exists, do nothing and move to next command\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir('VPA/MINIML')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir('VPA/Datasets')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir('VPA/GSM_Tables')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir('VPA/Info')\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..............................................................] 13491826 / 13491826"
     ]
    }
   ],
   "source": [
    "# downloading MINIML format\n",
    "\n",
    "missingFileList=[]\n",
    "output_fileName='VPA/Info/vpa_f1_extractMINIML_missingFiles.txt'\n",
    "ds=pd.read_csv('VPA/Info/vpa_search_f1.csv')\n",
    "for i in ds['DataLink']:\n",
    "    try:\n",
    "        wget.download(i,'VPA/MINIML')\n",
    "        time.sleep(0.34)\n",
    "    except:\n",
    "        missingFileList.append(i)\n",
    "\n",
    "if missingFileList!=[]: #if there are missing files\n",
    "    output_fileObject=open(output_fileName, \"w\") #create new text file\n",
    "    for i in missingFileList:\n",
    "        outputStringToPrint=str(i)+\"\\n\"\n",
    "        output_fileObject.write(outputStringToPrint) \n",
    "\n",
    "output_fileObject.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data to 'Datasets' folder\n",
    "\n",
    "os.chdir('VPA/MINIML')\n",
    "\n",
    "for file in os.listdir('./'):\n",
    "    os.mkdir('VPA/Datasets/'+file)\n",
    "\n",
    "for file in os.listdir('./'):\n",
    "    try:\n",
    "        tar=tf.open(file)\n",
    "        tar.extractall(path='VPA/Datasets/'+file)\n",
    "        tar.close\n",
    "    except: continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extracting GSM meta data from xml files\n",
    "\n",
    "os.chdir('VPA/Datasets/')\n",
    "dirs=os.listdir()\n",
    "\n",
    "for ts in dirs:\n",
    "    os.chdir('VPA/Datasets/'+ts+'/')\n",
    "    lst=os.listdir()\n",
    "\n",
    "    for i in lst:\n",
    "        if i.find('xml')>-1:\n",
    "            xml=i\n",
    "        else: continue\n",
    "    try: ids=ET.parse(xml).getroot()\n",
    "    except: \n",
    "        misFile=open('VPA/GSM_Tables/'+ts+'.txt', 'w')\n",
    "        misFile.write('There is no xml file, check other formats')\n",
    "        misFile.close()\n",
    "    \n",
    "    # information about data processing\n",
    "    prefix='{http://www.ncbi.nlm.nih.gov/geo/info/MINiML}'\n",
    "    gsm=list()\n",
    "    gpl=list()\n",
    "    procInf=list()\n",
    "    gse=list()\n",
    "    chrs=list()\n",
    "    desc=list()\n",
    "    columns=list()\n",
    "    organism=list()\n",
    "    source=list()\n",
    "    \n",
    "    # getting platform refernce number\n",
    "    for i in ids.findall(prefix+'Sample/'+prefix+'Platform-Ref'):\n",
    "        try: \n",
    "            platform=str(i.attrib.values())\n",
    "            platform=re.findall(\"'.+'\", platform)[0]\n",
    "            gpl.append(platform)    \n",
    "        except: gpl.append('check')    \n",
    "\n",
    "    # getting ifor about data processing in the series\n",
    "    for i in ids.findall(prefix+'Sample/'+prefix+'Data-Processing'):\n",
    "        try: procInf.append(i.text.strip())    \n",
    "        except: procInf.append('check')    \n",
    "\n",
    "    # GSM accession number        \n",
    "    for i in ids.findall(prefix+'Sample/'+prefix+'Accession'):\n",
    "        try: gsm.append(i.text.strip())   \n",
    "        except: gsm.append('check')\n",
    "        gse.append(re.findall('GSE.+\\d',xml)[0])\n",
    "\n",
    "    # sample characteristics information    \n",
    "    for i in ids.iter(prefix+'Sample'):\n",
    "        chnl=list()\n",
    "        for z in i.iter(prefix+'Channel'):\n",
    "            chnl.append(z.tag)\n",
    "        if len(chnl) == 1:\n",
    "            chr=''\n",
    "            for x in z.iter(prefix+'Characteristics'):\n",
    "                try:\n",
    "                    val=str(x.attrib.values()).strip()\n",
    "                    val=re.findall(\"'.+'\", val)[0]\n",
    "                    chr=chr+val+' : '+x.text.strip()+',    '\n",
    "                except: chr='Nothing here'\n",
    "            chrs.append(chr)\n",
    "            orgs=list()\n",
    "            for t in z.iter(prefix+'Organism'):\n",
    "                orgs.append(t.text)\n",
    "            orgs=' + '.join(orgs)\n",
    "            organism.append(orgs)\n",
    "            for n in z.iter(prefix+'Source'):\n",
    "                source.append(n.text)\n",
    "        else: \n",
    "            chrs.append('Multiple channels: '+str(len(chnl)))\n",
    "            organism.append('Multiple channels: '+str(len(chnl)))\n",
    "            for n in z.iter(prefix+'Source'):\n",
    "                source.append(n.text)\n",
    "            \n",
    "    # Sample description        \n",
    "    for i in ids.iter(prefix+'Sample'):\n",
    "        a='no data'\n",
    "        des=i.findall(prefix+'Description')\n",
    "        if len(des)>0:\n",
    "            for z in des:\n",
    "                desc.append(z.text.strip())\n",
    "        else: \n",
    "            desc.append(a)\n",
    "\n",
    "    # column headings in data files\n",
    "    for i in ids.iter(prefix+'Sample'):\n",
    "        for z in i.iter(prefix+'Data-Table'):\n",
    "            colnms=''\n",
    "            for x in z.findall(prefix+'Column/'+prefix+'Name'):\n",
    "                colnms=colnms+'   '+x.text\n",
    "        columns.append(colnms)\n",
    "\n",
    "    sumFile=pd.DataFrame({'GSE':gse,'GPL':gpl,'GSM':gsm,'Organism':organism,'SampleInfo':chrs,\n",
    "                     'SampleDesc':desc,'SampleSource':source,'ProcessingInfo':procInf,'ColNames':columns})\n",
    "    sumFile.to_csv('VPA/GSM_Tables/'+xml+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining meta-data for each GSM\n",
    "\n",
    "os.chdir('VPA/GSM_Tables/')\n",
    "gsm=os.listdir('.')\n",
    "\n",
    "ds=pd.read_csv(gsm[0])\n",
    "for i in range(len(gsm)-1):\n",
    "    ind=i+1\n",
    "    ds1=pd.read_csv(gsm[ind])\n",
    "    ds=pd.concat([ds,ds1])\n",
    "\n",
    "ds.to_csv('../Info/GSM-Meta_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('VPA/GSM_Merged')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining GSMs from all GSEs into one table\n",
    "\n",
    "\n",
    "for gseSet in os.listdir('VPA/Datasets/'):\n",
    "    print(gseSet)\n",
    "    data=pd.DataFrame()\n",
    "    z=pd.DataFrame()\n",
    "    lst=os.listdir('VPA/Datasets/'+gseSet)\n",
    "    for gpl in lst:\n",
    "        if gpl.startswith('GPL'):\n",
    "            #data=pd.read_table(gseSet+'/'+gpl,header=None)\n",
    "            data=pd.read_table('VPA/Datasets/'+gseSet+'/'+gpl,header=None)\n",
    "            data=data.rename(columns={0:'ID'})\n",
    "        else: continue\n",
    "\n",
    "    for i in lst:\n",
    "        if i.startswith('GSM'):\n",
    "            #z=pd.read_table(gseSet+'/'+i,header=None)\n",
    "            z=pd.read_table('VPA/Datasets/'+gseSet+'/'+i,header=None)\n",
    "            z=z.iloc[:,0:2]\n",
    "            z.columns=['ID',i]\n",
    "            try:\n",
    "                data=pd.merge(data,z,on='ID',how='right')\n",
    "                print(\"ok\")\n",
    "            except: continue\n",
    "        else: continue\n",
    "\n",
    "    data.to_csv('VPA/GSM_Merged/'+gseSet+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
